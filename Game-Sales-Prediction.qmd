---
title: "Game_Sales_Report"
format: pdf
editor: visual
---

Group 18: Adeer Siddiqui, Tuan Pham, Uyen Vi Phan

Spring 2025

## 1. Introduction // Tuan Pham

For our project, we decided to analyze the `global video game sales` data from 2024, sourced from Kaggle.com. Our inspiration comes from our love for video games and we are curious about which factors determine a video game’s success. This dataset has `64017 rows` with `14 columns`. The variables are listed below:

`img`: An url to an image of the game packaging on vgchartz.com

`title` : The title of the game

`console` : The console the game is released for

`genre` : The genre of the game

`publisher` : The publisher of the game

`developer`: The developer of the game

`critic_score`: The metacritic score (out of 10)

`total_sales` : Total sales globally in millions of USD

`na_sales` : North American sales in millions of USD

`jp_sales` : Japanese sales in millions of USD

`pal_sales` : European & African sales in millions of USD

`other_sales` : Rest of world sales of copies in millions of USD

`release_date` : Date the game was released on

`last_update` : Date the data was last updated

Of the 14 variables, our group will most likely be examining the `console`, `genre`, `publisher`, `developer`, `critic score`, and `release date` (mostly focusing on the month) as potential predictors. The `title` of the game and the`img` serve as an identifier and are solely unique to each game, so they will not contribute to sales prediction. Sales in individual countries are irrelevant as we are focused on predicting `total_sales`. We drop the `last_update` variable because it likely reflects when the dataset entry was edited, not something about the game itself. It’s not informative for sales analysis and keeping it might mislead people into thinking it's an in-game update date, which it’s probably not. Our response variable will be `total_sales`.

Our primary objective is to predict video game sales based on `genre`, `publisher`, `developer`, `critic score`, and `release month`. Our main question is: what is the predicted total sales of a game based on `genre`, `publisher`, `developer`, `critic score`, and `release month`. The models we want to examine for this project are Linear Regression and Decision Tree, and use cross-validation for model comparison. Using both models together allows us to compare results and identify the best approach for predicting game sales.

There are 4 main tasks for this project: data preparation, creating the first model, creating the second model, and interpreting the models into the report. Tuan Pham worked on data preparation and assist the other group members build their models. Uyen Vi Phan created and analyzed the Linear Regression model, and Adeer Siddiqui created and analyzed the Decision Tree Model. Then our group combined and discussed our works to make the final report.

\newpage

## 2. Linear Regression // Uyen Vi Phan

Linear Regression is a parametric model that seeks to represent the relationship between the output and input variables linearly. Our objective is to be able to predict and find the factors that affect the `total_sales` of [global video game sales data from 2024](https://www.kaggle.com/datasets/hosammhmdali/video-game-sales-2024). Our group decided to choose Linear Regression to model our data because it provides a simple linear equation that can be easily calculated by hand. It gives us weights for each predictor that indicate how much `total_sales` changes with one unit increase or decrease of each of our predictors.

In addition to this, Linear Regression offers a simple and interpretative method that can be used to predict `total_sales`. However, due to its simplicity, it has trouble effectively modeling complex data and the data must fit specific assumptions for Linear Regression to be effective: the predictors must have a linear relationship with `total_sales` , each observation must be independent of one another, the data must be normally distributed, and they must have equal variance.

#### a. Model Equation

The Linear Regression model equation is displayed below: $$ y = \beta_0 + \beta_1x_1 + \beta_2x_2 + ... + \beta_nx_n + \epsilon$$

Where y represents our output variable, `total_sales`, $\beta_0$ represents our model intercept, $\beta_i$ is our coefficient for our predictor $x_i$ and $\epsilon$ is our error term.

#### b. Process

In order to properly fit the model to our data, we must exclude some of our data that may have no affect on the `total_sales`. Our initial data cleanup already removed a lot of unnecessary variables, but we could go even further. I initially attempted to pick which predictors to keep using their p-values. I quickly realized that since our data has so many categorical variables with a lot of categories, eliminating predictors based on p-values was not efficient. The output is withheld due to the length of the results.

```{r}
#| output: false
library(readr)
game <- read_csv("game.csv")
attach(game)

game.lm = lm(total_sales ~ ., data = game)
summary(game.lm)
```

The method for determining what predictors are significant in predicting `total_sales` that worked is backwards stepwise regression using the `step()` function, which ended up working fine. Stepwise regression concluded that `console`, `genre`, `publisher`, `critic_score` and `release_month` were significant in predicting `total_sales`. The output is withheld due to the length of the results.

```{r}
#| output: false
step(game.lm)
```

However, when it came to validating the data, another problem came up. Since our data has so many categorical variables with many different categories, sometimes all the observations under one category could end up in the test set and never appear in the training set, leading to an error because the model is not trained to predict `total_sales` using that specific category. To remedy this, I first looked at all the categories from each categorical predictor and checked their frequencies. I decided remove `publisher` and `developer` from consideration, as they had over 200 different categories. Including them could lead to overfitting our model. `genre` and `console` only had less than 30 categories, so they could still be significant in predicting `total_sales`. I then repeated the `step()` function again on the remaining variables. The `step()` function concluded that `console`, `genre`, `critic_score` and `release_month` were significant in predicting `total_sales`.

```{r}
game.pub.types = table(game$publisher)
View(game.pub.types)
game.dev.types = table(game$developer)
View(game.dev.types)
game.gen.types = table(game$genre)
View(game.gen.types)
game.con.types = table(game$console)
View(game.con.types)

game.lm = lm(total_sales ~ console+genre+critic_score+release_month, data = game)
step(game.lm)
```

#### c. Validation

In order to verify how well our model predicts `total_sales` to new data, we must perform cross-validation to obtain the average Mean Squared Error. For this model, we performed the validation method 10 times. Despite removing `publisher` and `developer` from the model, we still had the issue where whole categories will go into the testing set, however not to as a severe degree as before. Because of this, it was easy to find a set of seeds that do not yield this error.

```{r}
workable_seeds = c(3, 6, 7, 8, 10, 11, 13, 14, 17, 22)

game.lm.MSE=rep(0,10)
for (i in 1:10){
  set.seed(workable_seeds[i])
  game.sample = sample(1:nrow(game),nrow(game)*0.8)
  game.train = game[game.sample,]
  game.test = game[-game.sample,]
  
  game.lm = lm(total_sales ~ console + genre  + critic_score + 
                 release_month, data = game.train)
  
  game.pred = predict(game.lm, newdata=game.test)
  game.lm.MSE[i]= mean((game.pred-game.test$total_sales)^2)
}

mean(game.lm.MSE)
```

#### d. Results

Here is the resulting linear regression model that best predicts `total_sales` .

```{r}
game.lm = lm(total_sales ~ console + genre  + critic_score + release_month, data = game)
summary(game.lm)
```

The chosen predictord are `console`, `genre`, `critic_score` and `release_month`, with `critic_score` and `release_month` being the most significant based on their p-values. The average MSE from performing cross-validation in part C is `1.39` which will be compared to the Decision Tree. Though I predict that it may be higher than the decision tree because of the many categorical predictors in our data. They do not form a linear relationship with `total_sales` which is needed for Linear Regression to be effective.

\newpage

## 3. Decision Tree // Adeer Siddiqui

A decision tree models the relationship between input and output variables by using a series of nodes that branch based on certain variables until they reach a terminal node, which represents the final estimation of the output. The decision tree model is useful to analyze this dataset because it is able to account for a number of different variables and have a complex system of priorities, where one variable may not be considered more significant than another unless certain conditions are met in a particular case.

Decision trees tend to be incredibly easy and intuitive to read and interpret, since it involves a simple true/false statement at every single node, which can be used to branch until a terminal node is reached for an estimation. The possibility of overfitting, however, is quite present in decision trees, since the degree of complexity they allow can be so extreme that it may only work on the training set, and fail to account for any variable scenarios.

#### a. Model Equation

There is no set equation for the decision tree model, as the tree was generated for this particular dataset using the below command:

```{r}
#| output: false
#| eval: false
game.tree <- tree(total_sales ~ ., data = game)
```

#### b. Process

As done with the linear regression model, we excluded the variables that may have no effect on the `total_sales` or may cause issues that prevent the model from functioning properly. This means that the variables used to predict `total_sales` with the decision tree model were `console`, `genre`,`critic_score`, and `release_month`.

```{r}
#| output: false
#| eval: false
game.tree <- tree(total_sales ~ ., data = game)
plot(game.tree)
text(game.tree, pretty = 0)
```

Using the above code to generate the decision tree model, we were able to produce this output:

![](images/clipboard-402514387.png)

#### c. Cross Validation

In order to test the generated tree, we performed cross-validation to obtain the average Mean Squared Error, validating a total of 10 times. In order to maintain consistency with the linear regression model, we used the same set of 10 seeds to test the decision tree model.

Alongside testing the decision tree, we also generated a pruned decision tree at every iteration, testing to see if it would produce an improved MSE. This was all performed in the same loop, for which the code is below:

```{r}
#| output: false
#| eval: false
workable_seeds <- c(3,6,7,8,10,11,13,14,17,22)
game.tree.MSE <- rep(0,10)
game.pruned.MSE <- rep(0,10)
for (i in 1:10) {
  set.seed(workable_seeds[i])
  # Train/Test decision tree
  game.sample <- sample(1:nrow(game), nrow(game) * 0.8)
  game.train <- game[game.sample, ]
  game.test <- game[-game.sample, ]
  game.tree <- tree(total_sales ~ ., data = game.train)
  game.pred <- predict(game.tree, newdata = game.test)
  game.tree.MSE[i] = mean((game.pred - game.test$total_sales)^2)
  
  # Cross Validation
  cv.game.tree <- cv.tree(game.tree)
  best.size <- cv.game.tree$size[which.min(cv.game.tree$dev)]
  
  # Generate pruned decision tree
  game.pruned.tree <- prune.tree(game.tree, best = best.size)
  
  # Test pruned decision tree
  game.pruned.pred <- predict(game.pruned.tree, newdata = game.test)
  game.pruned.MSE[i] <- mean((game.pruned.pred - game.test$total_sales)^2)
  
}
```

Below is an example of a pruned tree, with this specific one having been generated with seed `3`.

![](images/clipboard-1755941658.png)

#### d. Results

At the end of the loop, we printed the full list of MSE for each iteration of the original decision tree and pruned tree, followed by the average MSE over all tests for each model.

```{r}
#| output: false
#| eval: false
# Output MSE of decision trees
game.tree.MSE
game.pruned.MSE

# Output average MSE of decision trees
mean(game.tree.MSE)
mean(game.pruned.MSE)
```

The average MSE of the original decision tree was `1.558671`. The average MSE of the pruned decision tree was `1.583467`.

The pruned decision tree had a higher MSE, meaning that the pruning of the tree made the model less accurate in predicting the output from the four input variables.

\newpage

## 4. Conclusion// Uyen Vi Phan

In order to find the best way to predict the best the `total_sales` a game will make based on `console`, `genre`, `critic_score` and `release_month`, we examined 2 different models: Linear Regression and Decision Trees. Both models have a focus on simplicity and interpretability that make the models ideal for an average person to predict how well their game will do. The effectiveness of both these models will be evaluated using the MSE.

As our previous analyses on our game data has shown, the Linear Regression model actually yielded the lowest MSE with a value of `1.39`, making it the most effective at computing `total_sales`. The single decision tree yielded an MSE of `1.56` and the pruned decision tree yielded a MSE of `1.58` this could show that our predictors share a linear relationship with `total_sales`.

These findings will be valuable to game developers to get a general idea of how successful their game will be. It will also provide insight into the general audience's interest into what type of games they enjoy, and what factors they consider before purchasing a game.

\newpage

## 5. Bibliography

-    Data set: <https://www.kaggle.com/datasets/hosammhmdali/video-game-sales-2024>

## 6. Source Code

#### a. Code for Data Preparation//Tuan Pham

```{r}
#| output: false
#| eval: false
#include necessary library
library(tidyverse)
library(lubridate)
library(dplyr)
#extract and get the predictors column that we are interested in
game <- game %>% select(c("genre", "publisher", "developer", "critic_score", "total_sales", "release_date"))
#extract and get the month from release_date
game$release_month <- month(game$release_date)
#drop the missing values and last unnecessary column
game <- game %>% select(-c("release_date"))
game <- na.omit(game)
#change categorical variables'data type from text to factor for easier processing
game$console <- factor(game$console)
game$genre <- factor(game$genre)
game$publisher <- factor(game$publisher)
game$developer <- factor(game$developer)
```

#### b. Code for Linear Regression //Uyen Vi Phan

```{r}
#| output: false
#| eval: false
library(readr)
game <- read_csv("game.csv")
#View(game)
attach(game)

#check how many categories in each colum
categories <- unique(game$console) 
length(categories)
categories <- unique(game$genre) 
length(categories)
categories <- unique(game$publisher) 
length(categories)
categories <- unique(game$developer) 
length(categories)
categories <- unique(game$console) 
length(categories)

#view frequency of each column
game.pub.types = table(game$publisher)
#View(game.pub.types)
game.dev.types = table(game$developer)
#View(game.dev.types)
game.gen.types = table(game$genre)
#View(game.gen.types)
game.con.types = table(game$console)
#View(game.con.types)

game.lm = lm(total_sales ~ console+genre+critic_score+release_month, data = game)
summary(game.lm) #cant use t-test bc of the categorial vars


step(game.lm) #backwards stepwise regression

set.seed(22) #keep incrementing until find good seed
game.sample = sample(1:nrow(game),nrow(game)*0.8)
game.train = game[game.sample,]
game.test = game[-game.sample,]

game.lm = lm(total_sales ~ console+genre+critic_score+release_month, data = game)

game.pred = predict(game.lm, newdata = game.test)
game.lm.MSE= mean((game.pred-game.test$total_sales)^2)


workable_seeds = c(3, 6, 7, 8, 10, 11, 13, 14, 17, 22)

game.lm.MSE=rep(0,10)
for (i in 1:10){
  set.seed(workable_seeds[i])
  game.sample = sample(1:nrow(game),nrow(game)*0.8)
  game.train = game[game.sample,]
  game.test = game[-game.sample,]
  
  game.lm = lm(total_sales ~ console + genre  + critic_score + 
                 release_month, data = game.train)
  
  game.pred = predict(game.lm, newdata=game.test)
  game.lm.MSE[i]= mean((game.pred-game.test$total_sales)^2)
}

game.lm.MSE
```

#### c. Code for Regression Tree//Adeer Siddiqui

```{r}
#| output: false
#| eval: false
# Import libraries and dataset
library(tidyverse)
library(readr)
library(tree)
game <- read_csv("game.csv")

# Remove publisher and developer
game <- game %>% select(c("console", "genre", "critic_score", "total_sales", "release_month"))

# Generate decision tree
game.tree <- tree(total_sales ~ ., data = game)
plot(game.tree)
text(game.tree, pretty = 0)

workable_seeds <- c(3,6,7,8,10,11,13,14,17,22)
game.tree.MSE <- rep(0,10)
game.pruned.MSE <- rep(0,10)
for (i in 1:10) {
  set.seed(workable_seeds[i])
  # Train/Test decision tree
  game.sample <- sample(1:nrow(game), nrow(game) * 0.8)
  game.train <- game[game.sample, ]
  game.test <- game[-game.sample, ]
  game.tree <- tree(total_sales ~ ., data = game.train)
  game.pred <- predict(game.tree, newdata = game.test)
  game.tree.MSE[i] = mean((game.pred - game.test$total_sales)^2)
  
  # Cross Validation
  cv.game.tree <- cv.tree(game.tree)
  best.size <- cv.game.tree$size[which.min(cv.game.tree$dev)]
  
  # Generate pruned decision tree
  game.pruned.tree <- prune.tree(game.tree, best = best.size)
  
  # Test pruned decision tree
  game.pruned.pred <- predict(game.pruned.tree, newdata = game.test)
  game.pruned.MSE[i] <- mean((game.pruned.pred - game.test$total_sales)^2)
  
}

# Output MSE of decision trees
game.tree.MSE
game.pruned.MSE

# Output average MSE of decision trees
mean(game.tree.MSE)
mean(game.pruned.MSE)
```

\newpage
